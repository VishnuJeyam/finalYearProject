# finalYearProject
Accurate medical image segmentation is essential for detecting fine structures such as micro-lesions and thin retinal vessels. Traditional high-resolution segmentation approaches require large inputs, leading to high computational cost and limited deployment in real-time systems. To address this, we propose a Dual-Stream Shared Feature Learning Framework that jointly performs segmentation and an auxiliary task of super-resolution. The framework consists of a Shared Feature Extraction Module (SFEM) to capture robust multi-scale representations, followed by dual decoders for segmentation and super-resolution. A Multi-Scale Cross Gate (MSCG) mechanism selectively shares only the most relevant features between the two tasks, ensuring that fine details are preserved. Additionally, a proxy task with proxy loss is employed to explicitly guide the model toward small but clinically important structures. Experiments on multiple retinal image datasets demonstrate that the proposed framework improves segmentation accuracy for small targets while reducing computational complexity, making it more suitable for real-time and portable medical imaging applications.
